{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import uuid\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23), (30, 61), (62, 45), (59, 119), (116, 90), (156, 198), (373, 326)]\n",
    "\n",
    "\n",
    "def darknet53(inputs):\n",
    "    \"\"\"\n",
    "    Builds Darknet-53 model.\n",
    "    \"\"\"\n",
    "    inputs = _conv2d_fixed_padding(inputs, 32, 3)\n",
    "    inputs = _conv2d_fixed_padding(inputs, 64, 3, strides=2)\n",
    "    inputs = _darknet53_block(inputs, 32)\n",
    "    inputs = _conv2d_fixed_padding(inputs, 128, 3, strides=2)\n",
    "\n",
    "    for i in range(2):\n",
    "        inputs = _darknet53_block(inputs, 64)\n",
    "\n",
    "    inputs = _conv2d_fixed_padding(inputs, 256, 3, strides=2)\n",
    "\n",
    "    for i in range(8):\n",
    "        inputs = _darknet53_block(inputs, 128)\n",
    "\n",
    "    route_1 = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, 512, 3, strides=2)\n",
    "\n",
    "    for i in range(8):\n",
    "        inputs = _darknet53_block(inputs, 256)\n",
    "\n",
    "    route_2 = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, 1024, 3, strides=2)\n",
    "\n",
    "    for i in range(4):\n",
    "        inputs = _darknet53_block(inputs, 512)\n",
    "\n",
    "    return route_1, route_2, inputs\n",
    "\n",
    "\n",
    "def _conv2d_fixed_padding(inputs, filters, kernel_size, strides=1):\n",
    "    if strides > 1:\n",
    "        inputs = _fixed_padding(inputs, kernel_size)\n",
    "    inputs = slim.conv2d(inputs, filters, kernel_size, stride=strides, padding=('SAME' if strides == 1 else 'VALID'))\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def _darknet53_block(inputs, filters):\n",
    "    shortcut = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters * 2, 3)\n",
    "\n",
    "    inputs = inputs + shortcut\n",
    "    return inputs\n",
    "\n",
    "\n",
    "@tf.contrib.framework.add_arg_scope\n",
    "def _fixed_padding(inputs, kernel_size, *args, mode='CONSTANT', **kwargs):\n",
    "    \"\"\"\n",
    "    Pads the input along the spatial dimensions independently of input size.\n",
    "    Args:\n",
    "      inputs: A tensor of size [batch, channels, height_in, width_in] or\n",
    "        [batch, height_in, width_in, channels] depending on data_format.\n",
    "      kernel_size: The kernel to be used in the conv2d or max_pool2d operation.\n",
    "                   Should be a positive integer.\n",
    "      data_format: The input format ('NHWC' or 'NCHW').\n",
    "      mode: The mode for tf.pad.\n",
    "    Returns:\n",
    "      A tensor with the same format as the input with the data either intact\n",
    "      (if kernel_size == 1) or padded (if kernel_size > 1).\n",
    "    \"\"\"\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "\n",
    "    if kwargs['data_format'] == 'NCHW':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
    "                                        [pad_beg, pad_end], [pad_beg, pad_end]], mode=mode)\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end], [0, 0]], mode=mode)\n",
    "    return padded_inputs\n",
    "\n",
    "\n",
    "def _yolo_block(inputs, filters):\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters * 2, 3)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters * 2, 3)\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters, 1)\n",
    "    route = inputs\n",
    "    inputs = _conv2d_fixed_padding(inputs, filters * 2, 3)\n",
    "    return route, inputs\n",
    "\n",
    "\n",
    "def _get_size(shape, data_format):\n",
    "    if len(shape) == 4:\n",
    "        shape = shape[1:]\n",
    "    return shape[1:3] if data_format == 'NCHW' else shape[0:2]\n",
    "\n",
    "\n",
    "def _detection_layer(inputs, num_classes, anchors, img_size, data_format):\n",
    "    num_anchors = len(anchors)\n",
    "    predictions = slim.conv2d(inputs, num_anchors * (5 + num_classes), 1, stride=1, normalizer_fn=None,\n",
    "                              activation_fn=None, biases_initializer=tf.zeros_initializer())\n",
    "\n",
    "    shape = predictions.get_shape().as_list()\n",
    "    grid_size = _get_size(shape, data_format)\n",
    "    dim = grid_size[0] * grid_size[1]\n",
    "    bbox_attrs = 5 + num_classes\n",
    "\n",
    "    if data_format == 'NCHW':\n",
    "        predictions = tf.reshape(predictions, [-1, num_anchors * bbox_attrs, dim])\n",
    "        predictions = tf.transpose(predictions, [0, 2, 1])\n",
    "\n",
    "    predictions = tf.reshape(predictions, [-1, num_anchors * dim, bbox_attrs])\n",
    "\n",
    "    stride = (img_size[0] // grid_size[0], img_size[1] // grid_size[1])\n",
    "\n",
    "    anchors = [(a[0] / stride[0], a[1] / stride[1]) for a in anchors]\n",
    "\n",
    "    box_centers, box_sizes, confidence, classes = tf.split(predictions, [2, 2, 1, num_classes], axis=-1)\n",
    "\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "\n",
    "    grid_x = tf.range(grid_size[0], dtype=tf.float32)\n",
    "    grid_y = tf.range(grid_size[1], dtype=tf.float32)\n",
    "    a, b = tf.meshgrid(grid_x, grid_y)\n",
    "\n",
    "    x_offset = tf.reshape(a, (-1, 1))\n",
    "    y_offset = tf.reshape(b, (-1, 1))\n",
    "\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    x_y_offset = tf.reshape(tf.tile(x_y_offset, [1, num_anchors]), [1, -1, 2])\n",
    "\n",
    "    box_centers = box_centers + x_y_offset\n",
    "    box_centers = box_centers * stride\n",
    "\n",
    "    anchors = tf.tile(anchors, [dim, 1])\n",
    "    box_sizes = tf.exp(box_sizes) * anchors\n",
    "    box_sizes = box_sizes * stride\n",
    "\n",
    "    detections = tf.concat([box_centers, box_sizes, confidence], axis=-1)\n",
    "\n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "    predictions = tf.concat([detections, classes], axis=-1)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def _upsample(inputs, out_shape, data_format='NCHW'):\n",
    "    # tf.image.resize_nearest_neighbor accepts input in format NHWC\n",
    "    if data_format == 'NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "\n",
    "    if data_format == 'NCHW':\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "\n",
    "    # back to NCHW if needed\n",
    "    if data_format == 'NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    inputs = tf.identity(inputs, name='upsampled')\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def yolo_v3(inputs, num_classes, is_training=False, data_format='NCHW', reuse=False):\n",
    "    \"\"\"\n",
    "    Creates YOLO v3 model.\n",
    "    :param inputs: a 4-D tensor of size [batch_size, height, width, channels].\n",
    "        Dimension batch_size may be undefined. The channel order is RGB.\n",
    "    :param num_classes: number of predicted classes.\n",
    "    :param is_training: whether is training or not.\n",
    "    :param data_format: data format NCHW or NHWC.\n",
    "    :param reuse: whether or not the network and its variables should be reused.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # it will be needed later on\n",
    "    img_size = inputs.get_shape().as_list()[1:3]\n",
    "\n",
    "    # transpose the inputs to NCHW\n",
    "    if data_format == 'NCHW':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    # normalize values to range [0..1]\n",
    "    inputs = inputs / 255\n",
    "\n",
    "    # set batch norm params\n",
    "    batch_norm_params = {\n",
    "        'decay': _BATCH_NORM_DECAY,\n",
    "        'epsilon': _BATCH_NORM_EPSILON,\n",
    "        'scale': True,\n",
    "        'is_training': is_training,\n",
    "        'fused': None,  # Use fused batch norm if possible.\n",
    "    }\n",
    "\n",
    "    # Set activation_fn and parameters for conv2d, batch_norm.\n",
    "    with slim.arg_scope([slim.conv2d, slim.batch_norm, _fixed_padding], data_format=data_format, reuse=reuse):\n",
    "        with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, normalizer_params=batch_norm_params,\n",
    "                            biases_initializer=None, activation_fn=lambda x: tf.nn.leaky_relu(x, alpha=_LEAKY_RELU)):\n",
    "            with tf.variable_scope('darknet-53'):\n",
    "                route_1, route_2, inputs = darknet53(inputs)\n",
    "\n",
    "            with tf.variable_scope('yolo-v3'):\n",
    "                route, inputs = _yolo_block(inputs, 512)\n",
    "                detect_1 = _detection_layer(inputs, num_classes, _ANCHORS[6:9], img_size, data_format)\n",
    "                detect_1 = tf.identity(detect_1, name='detect_1')\n",
    "\n",
    "                inputs = _conv2d_fixed_padding(route, 256, 1)\n",
    "                upsample_size = route_2.get_shape().as_list()\n",
    "                inputs = _upsample(inputs, upsample_size, data_format)\n",
    "                inputs = tf.concat([inputs, route_2], axis=1 if data_format == 'NCHW' else 3)\n",
    "\n",
    "                route, inputs = _yolo_block(inputs, 256)\n",
    "\n",
    "                detect_2 = _detection_layer(inputs, num_classes, _ANCHORS[3:6], img_size, data_format)\n",
    "                detect_2 = tf.identity(detect_2, name='detect_2')\n",
    "\n",
    "                inputs = _conv2d_fixed_padding(route, 128, 1)\n",
    "                upsample_size = route_1.get_shape().as_list()\n",
    "                inputs = _upsample(inputs, upsample_size, data_format)\n",
    "                inputs = tf.concat([inputs, route_1], axis=1 if data_format == 'NCHW' else 3)\n",
    "\n",
    "                _, inputs = _yolo_block(inputs, 128)\n",
    "\n",
    "                detect_3 = _detection_layer(inputs, num_classes, _ANCHORS[0:3], img_size, data_format)\n",
    "                detect_3 = tf.identity(detect_3, name='detect_3')\n",
    "\n",
    "                detections = tf.concat([detect_1, detect_2, detect_3], axis=1)\n",
    "                detections = tf.identity(detections, name='detections')\n",
    "                return detections\n",
    "\n",
    "\n",
    "def load_weights(var_list, weights_file):\n",
    "    \"\"\"\n",
    "    Loads and converts pre-trained weights.\n",
    "    :param var_list: list of network variables.\n",
    "    :param weights_file: name of the binary file.\n",
    "    :return: list of assign ops\n",
    "    \"\"\"\n",
    "    with open(weights_file, \"rb\") as fp:\n",
    "        _ = np.fromfile(fp, dtype=np.int32, count=5)\n",
    "\n",
    "        weights = np.fromfile(fp, dtype=np.float32)\n",
    "\n",
    "    ptr = 0\n",
    "    i = 0\n",
    "    assign_ops = []\n",
    "    while i < len(var_list) - 1:\n",
    "        var1 = var_list[i]\n",
    "        var2 = var_list[i + 1]\n",
    "        # do something only if we process conv layer\n",
    "        if 'Conv' in var1.name.split('/')[-2]:\n",
    "            # check type of next layer\n",
    "            if 'BatchNorm' in var2.name.split('/')[-2]:\n",
    "                # load batch norm params\n",
    "                gamma, beta, mean, var = var_list[i + 1:i + 5]\n",
    "                batch_norm_vars = [beta, gamma, mean, var]\n",
    "                for var in batch_norm_vars:\n",
    "                    shape = var.shape.as_list()\n",
    "                    num_params = np.prod(shape)\n",
    "                    var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                    ptr += num_params\n",
    "                    assign_ops.append(tf.assign(var, var_weights, validate_shape=True))\n",
    "\n",
    "                # we move the pointer by 4, because we loaded 4 variables\n",
    "                i += 4\n",
    "            elif 'Conv' in var2.name.split('/')[-2]:\n",
    "                # load biases\n",
    "                bias = var2\n",
    "                bias_shape = bias.shape.as_list()\n",
    "                bias_params = np.prod(bias_shape)\n",
    "                bias_weights = weights[ptr:ptr + bias_params].reshape(bias_shape)\n",
    "                ptr += bias_params\n",
    "                assign_ops.append(tf.assign(bias, bias_weights, validate_shape=True))\n",
    "\n",
    "                # we loaded 1 variable\n",
    "                i += 1\n",
    "            # we can load weights of conv layer\n",
    "            shape = var1.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape((shape[3], shape[2], shape[0], shape[1]))\n",
    "            # remember to transpose to column-major\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(var1, var_weights, validate_shape=True))\n",
    "            i += 1\n",
    "\n",
    "    return assign_ops\n",
    "\n",
    "\n",
    "def detections_boxes(detections):\n",
    "    \"\"\"\n",
    "    Converts center x, center y, width and height values to coordinates of top left and bottom right points.\n",
    "    :param detections: outputs of YOLO v3 detector of shape (?, 10647, (num_classes + 5))\n",
    "    :return: converted detections of same shape as input\n",
    "    \"\"\"\n",
    "    center_x, center_y, width, height, attrs = tf.split(detections, [1, 1, 1, 1, -1], axis=-1)\n",
    "    w2 = width / 2\n",
    "    h2 = height / 2\n",
    "    x0 = center_x - w2\n",
    "    y0 = center_y - h2\n",
    "    x1 = center_x + w2\n",
    "    y1 = center_y + h2\n",
    "\n",
    "    boxes = tf.concat([x0, y0, x1, y1], axis=-1)\n",
    "    detections = tf.concat([boxes, attrs], axis=-1)\n",
    "    return detections\n",
    "\n",
    "\n",
    "def _iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Computes Intersection over Union value for 2 bounding boxes\n",
    "    \n",
    "    :param box1: array of 4 values (top left and bottom right coords): [x0, y0, x1, x2]\n",
    "    :param box2: same as box1\n",
    "    :return: IoU\n",
    "    \"\"\"\n",
    "    b1_x0, b1_y0, b1_x1, b1_y1 = box1\n",
    "    b2_x0, b2_y0, b2_x1, b2_y1 = box2\n",
    "\n",
    "    int_x0 = max(b1_x0, b2_x0)\n",
    "    int_y0 = max(b1_y0, b2_y0)\n",
    "    int_x1 = min(b1_x1, b2_x1)\n",
    "    int_y1 = min(b1_y1, b2_y1)\n",
    "\n",
    "    int_area = (int_x1 - int_x0) * (int_y1 - int_y0)\n",
    "\n",
    "    b1_area = (b1_x1 - b1_x0) * (b1_y1 - b1_y0)\n",
    "    b2_area = (b2_x1 - b2_x0) * (b2_y1 - b2_y0)\n",
    "\n",
    "    # we add small epsilon of 1e-05 to avoid division by 0\n",
    "    iou = int_area / (b1_area + b2_area - int_area + 1e-05)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def non_max_suppression(predictions_with_boxes, confidence_threshold, iou_threshold=0.4):\n",
    "    \"\"\"\n",
    "    Applies Non-max suppression to prediction boxes.\n",
    "    :param predictions_with_boxes: 3D numpy array, first 4 values in 3rd dimension are bbox attrs, 5th is confidence\n",
    "    :param confidence_threshold: the threshold for deciding if prediction is valid\n",
    "    :param iou_threshold: the threshold for deciding if two boxes overlap\n",
    "    :return: dict: class -> [(box, score)]\n",
    "    \"\"\"\n",
    "    conf_mask = np.expand_dims((predictions_with_boxes[:, :, 4] > confidence_threshold), -1)\n",
    "    predictions = predictions_with_boxes * conf_mask\n",
    "\n",
    "    result = {}\n",
    "    for i, image_pred in enumerate(predictions):\n",
    "        shape = image_pred.shape\n",
    "        non_zero_idxs = np.nonzero(image_pred)\n",
    "        image_pred = image_pred[non_zero_idxs]\n",
    "        image_pred = image_pred.reshape(-1, shape[-1])\n",
    "\n",
    "        bbox_attrs = image_pred[:, :5]\n",
    "        classes = image_pred[:, 5:]\n",
    "        classes = np.argmax(classes, axis=-1)\n",
    "\n",
    "        unique_classes = list(set(classes.reshape(-1)))\n",
    "\n",
    "        for cls in unique_classes:\n",
    "            cls_mask = classes == cls\n",
    "            cls_boxes = bbox_attrs[np.nonzero(cls_mask)]\n",
    "            cls_boxes = cls_boxes[cls_boxes[:, -1].argsort()[::-1]]\n",
    "            cls_scores = cls_boxes[:, -1]\n",
    "            cls_boxes = cls_boxes[:, :-1]\n",
    "\n",
    "            while len(cls_boxes) > 0:\n",
    "                box = cls_boxes[0]\n",
    "                score = cls_scores[0]\n",
    "                if not cls in result:\n",
    "                    result[cls] = []\n",
    "                result[cls].append((box, score))\n",
    "                cls_boxes = cls_boxes[1:]\n",
    "                ious = np.array([_iou(box, x) for x in cls_boxes])\n",
    "                iou_mask = ious < iou_threshold\n",
    "                cls_boxes = cls_boxes[np.nonzero(iou_mask)]\n",
    "                cls_scores = cls_scores[np.nonzero(iou_mask)]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_coco_names(file_name):\n",
    "    names = {}\n",
    "    with open(file_name) as f:\n",
    "        for id, name in enumerate(f):\n",
    "            names[id] = name\n",
    "    return names\n",
    "\n",
    "\n",
    "def draw_boxes(boxes, img, cls_names, detection_size):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for cls, bboxs in boxes.items():\n",
    "        color = tuple([127,255,0])\n",
    "        for box, score in bboxs:\n",
    "            box = convert_to_original_size(box, np.array(detection_size), np.array(img.size))\n",
    "            draw.rectangle(box, outline=color)\n",
    "            draw.text(box[:2], '{} {:.2f}%'.format(cls_names[cls], score * 100), fill=color)\n",
    "\n",
    "\n",
    "def convert_to_original_size(box, size, original_size):\n",
    "    ratio = original_size / size\n",
    "    box = box.reshape(2, 2) * ratio\n",
    "    return list(box.reshape(-1))\n",
    "classes = load_coco_names(\"coco_classes.txt\")\n",
    "\n",
    "    # placeholder for detector inputs\n",
    "inputs = tf.placeholder(tf.float32, [None, 416, 416, 3])\n",
    "\n",
    "with tf.variable_scope('detector'):\n",
    "    detections = yolo_v3(inputs, len(classes), data_format='NCHW')\n",
    "    load_ops = load_weights(tf.global_variables(scope='detector'), \"yolov3.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img1=\"/home/eee/ug/15085004/yad2k/images/dog.jpg\"\n",
    "def predict(im=img1):\n",
    "    img = Image.open(im)\n",
    "    img_resized = img.resize(size=(416, 416))\n",
    "\n",
    "\n",
    "\n",
    "    boxes = detections_boxes(detections)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(load_ops)\n",
    "\n",
    "        detected_boxes = sess.run(boxes, feed_dict={inputs: [np.array(img_resized, dtype=np.float32)]})\n",
    "\n",
    "    filtered_boxes = non_max_suppression(detected_boxes, confidence_threshold=0.5,\n",
    "                                         iou_threshold=0.4)\n",
    "\n",
    "    draw_boxes(filtered_boxes, img, classes, (416, 416))\n",
    "    n=\"/home/eee/ug/15085004/img/\"+str(uuid.uuid4())+\".jpg\"\n",
    "    img.save(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.randint(0,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in glob.iglob(\"/home/eee/ug/15085004/yad2k/images/*.jpg\"):\n",
    "    img=Image.open(f)\n",
    "    predict(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(uuid.uuid4())+.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str(uuid.uuid4())+\".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
